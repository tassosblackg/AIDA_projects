# -*- coding: utf-8 -*-
"""Karageorgiadis_Neural_Network_Exams.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GCue_iKXHrwnkZqjm7QAwTlGoqaNb41c

# Install Data Libraries
"""

!pip install extra-keras-datasets

"""# **Reproducibility**"""

# Assure Reproducibility
from tensorflow import random
np.random.seed(1337)
random.set_seed(1337)

"""# Import Data and Libraries"""

import keras
import numpy as np
import matplotlib.pyplot as plt

from extra_keras_datasets import kmnist
(x_train, y_train), (x_test, y_test) = kmnist.load_data(type='kmnist')

# show 10 random images
for i in range(10):
  rand_index = np.random.choice(x_train.shape[0])
  rand_img = x_train[rand_index]
  plt.figure()
  plt.imshow(rand_img.reshape(28, 28))

"""# Reshape Data"""

num_classes = 10
input_shape = (28, 28, 1)

print('Input shape:',x_train.shape)
print('Target shape:',y_train.shape)

# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

print('Reshaped Input shape:',x_train.shape)
print('Reshaped Target shape:',y_train.shape)


# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)
print('Target shape after one-hot: ', y_test.shape)

"""#MinMax Normalization"""

_min = np.min(x_train)
_max = np.max(x_train)


#Before normalization
print(_min,_max)

# Min-Max normalization normal
x_train = (x_train-_min)/(_max -_min)
x_test = (x_test - _min) / (_max - _min)

"""# Define Helper Functions"""

def train_and_evaluate(model, epochs, batch_size):
  opt = keras.optimizers.Adam()
  model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"])
  history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)
  score = model.evaluate(x_test, y_test, verbose=0)
  return history, score

def print_and_plot(history, score, name):
  print(name+" Test loss:", score[0])
  print(name+" Test accuracy:", score[1])
  plt.plot(history.history['val_accuracy'], label='validation')
  plt.plot(history.history['accuracy'], label='train')
  plt.title(name+' Accuracy')
  plt.legend()
  plt.show()
  plt.figure()
  plt.plot(history.history['val_loss'], label='validation')
  plt.plot(history.history['loss'], label='train')
  plt.title(name+' Loss')
  plt.legend()

"""# Initial Model Definition"""



initial_model = keras.Sequential(
    [
        keras.Input(shape=input_shape),        
        keras.layers.Conv2D(filters=32, kernel_size=3, activation="relu"), 
        keras.layers.MaxPool2D(pool_size=2, strides=2), 
        keras.layers.Flatten(), 
        keras.layers.Dense(32, activation="relu"),
        keras.layers.Dense(num_classes, activation="softmax"),
    ]
)

initial_model.summary()
keras.utils.plot_model(initial_model)

"""# Model2"""

model2 = keras.Sequential(
    [
        keras.Input(shape=input_shape),        
        keras.layers.Conv2D(filters=32, kernel_size=3, activation="relu"), 
        keras.layers.Conv2D(filters=32, kernel_size=3, activation="relu"),
        keras.layers.MaxPool2D(pool_size=2, strides=2), 
        keras.layers.Flatten(), 
        keras.layers.Dense(32, activation="relu"),
        keras.layers.Dense(num_classes, activation="softmax"),
    ]
)

model2.summary()
keras.utils.plot_model(model2)

"""# Train, Evaluate and Present Results"""

history, score = train_and_evaluate(initial_model, epochs=10, batch_size=128)
print_and_plot(history, score, 'Initial Model')

"""# Initial Model with Adam optimizer instead of SGD"""

historyAd, scoreAd = train_and_evaluate(initial_model, epochs=10, batch_size=128)
print_and_plot(historyAd, scoreAd, 'Initial Model with Adam')

"""## **TrainModel2**"""

historyModel2, scoreModel2 = train_and_evaluate(model2, epochs=10, batch_size=128)
print_and_plot(historyModel2, scoreModel2, 'v2 Model with Adam')

"""# AddBatch"""

historyModel22, scoreModel22 = train_and_evaluate(model2, epochs=10, batch_size=256)
print_and_plot(historyModel22, scoreModel22, 'v2 Model with Adam,batchS=256')

"""# ΕΡΩΤΗΜΑ 1

---

**Αλλαγή 1** 

Προσθήκη σταθερου random_seed() για να μπορουμε να επαναλαμβανουμε τα ίδια αποτελέσματα από εκτέλεση σε εκτελεση της εκπαιδευσης

**Αλλαγή 2** 

Προσθήκη data normalization με τη μέθοδο minMax, είδαμε βελτίωση καθώς στο αρχικό run υπήρχε μεγάλο gap μεταξυ του training και validation curve τοσο στο loss όσο και στο accuracy.

**Αλλαγή 3**
Χρήση Adam() optimizer with default learning rate, βλέπουμε πως υπάρχει μία βελτίωση στο training accuracy/loss και το αποτελεσμα συγκλινει πιο γρηγορα ένω εμφανίζεται overfitting μετα απο 2-3 epochs. Για το ιδιο Num of epochs =10 batch_size =128.

#ΕΡΩΤΗΜΑ 2
---

**Αλλαγή 3**

Κατασκευή [model2](#Model2) με προσθήκη ενός ακόμη convolutional layer ακριβώς ίδιου με το πρώτο, βλέπουμε μία μικρή βελτίωση στο [validation accuracy](#TrainModel2) από 91 σε 92

**Αλλαγή 4** 
Αυξηση του [batch_size](#AddBatch) απο 128 σε 256, ωστόσο δεν παρατηρηθηκε κάποια βελτίωση.
"""