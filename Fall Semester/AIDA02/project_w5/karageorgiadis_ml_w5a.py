# -*- coding: utf-8 -*-
"""karageorgiadis_ml_w5a.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MqouTl4fUJnIdc8tmU47fBYJ3wkQ5ofz

# **ML  Week 5 - Mnist Dataset / Karageorgiadis**
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import  Flatten, Dense
from tensorflow.keras import Input
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical,plot_model
import numpy as np
import matplotlib.pyplot as plt

"""Read Data from Mnist"""

#
input_shape = (28,28,1)
output_size = 10

# keras load mnist dataset returns two numpy tuples
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# check type and shape
print("Train set shape :",x_train.shape,"data type : ",type(x_train))
print("Test set shape :",x_test.shape,"data type : ",type(x_test))
# Labels shape
print("Train labels shape :",y_train.shape,"data type : ",type(y_train))
print("Test labels shape :",y_test.shape,"data type : ",type(y_test))

"""Preprocessing"""

# Standarazation of input data using z-score method

# calculate mean and std up on train set for all instances
mean_train_set = np.mean(x_train)
std_train_set = np.std(x_train)

#z-score standarization both train and test sets
x_train = (x_train - mean_train_set)/std_train_set
x_test  = (x_test - mean_train_set)/std_train_set

# convert labels to ohe
y_train = to_categorical(y_train,output_size)
y_test = to_categorical(y_test,output_size)

"""Reshape Input"""

x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print("Train set shape :",x_train.shape,"data type : ",type(x_train))
print("Test set shape :",x_test.shape,"data type : ",type(x_test))

"""Build model"""

model = Sequential()
model.add(Input(input_shape))
model.add(Dense(32,activation='relu'))
model.add(Dense(18,activation='relu'))
model.add(Flatten())
model.add(Dense(64))
model.add(Dense(output_size,activation="softmax"))
#model.output_shape

"""Optimizer Options"""

model2=model
model3=model

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
# model2 SGD with momentum,default learning rate
opt2= SGD(learning_rate=0.01,momentum=0.5)
model2.compile(loss='categorical_crossentropy',optimizer=opt2,metrics=['accuracy'])
# model3 SGD without momentum
model3.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])



"""Plot Results Summaries"""

plot_model(model)

"""Summary"""

print(model.summary())

"""*** Model with Adam***"""

epochs=10
batch_size = 256
h1 = model.fit(x_train, y_train, validation_split=0.2, epochs = epochs, batch_size = batch_size)

"""Plot Accuracy graph"""

print(h1.history)

plt.plot(h1.history['accuracy'])
plt.plot(h1.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

scores1 = model.evaluate(x_test, y_test)
print("&*]\n%s: %.2f%%" % (model.metrics_names[1], scores1[1]*100))

"""***Model with SGD with momentum=0.5***"""

h2 = model2.fit(x_train, y_train, validation_split=0.2, epochs = epochs, batch_size = batch_size)

plt.plot(h2.history['accuracy'])
plt.plot(h2.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

scores2 = model2.evaluate(x_test, y_test)
print("&*]\n%s: %.2f%%" % (model2.metrics_names[1], scores2[1]*100))

"""***Model with SGD without momentum***"""

h3 = model3.fit(x_train, y_train, validation_split=0.2, epochs = epochs, batch_size = batch_size)

plt.plot(h3.history['accuracy'])
plt.plot(h3.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

scores3 = model3.evaluate(x_test, y_test)
print("&*]\n%s: %.2f%%" % (model3.metrics_names[1], scores3[1]*100))

"""# Comments for model
First of all I tried to create a more complicate model than the one presented at the lecture, so the new model is deeper and wider than the first one. This has as a result the increasion of total number of parameters to be learned. More detailed the 'new' model has 9 times more parameters than the 'old' one, `[904,540 vs 101,770]`.

This cause the total accuracy of the model to drop to *92%* from *98%*. As a general rule, while our model becomes more complex the more data, training, time, etc, are needed to have a good accuracy.


We used the same model, with three different optimizers *Adam*, *SGD with momentum=0.5*, and *SGD without momentum*. We see at the plots that Adam permorms better because train and test accuracy's curves are smoother, while the other two methods show many up and down peaks,at test accuracy, meaning that not finding the optimal prediction (stucks at some sub-optimal points while trying to minimize the loss function).

In general *Adam* optimizer is better option to choose for more complex models, cause *Adam* combines the best parts from both worlds. *Adam* is an adaptive moment optimizer based on *SGD* and *RMSprop*, so it adjust its momentum /learning rate  accordingly for each step, in order to find the optimal solution much faster and by avoiding the danger to stuck at sub-optimal solutions [see 2.3.3.6](https://dias.library.tuc.gr/view/84791). 

An other key difference between Adam and SGD is the learning rate Adam has lr=0.001,while SGD has lr=0.01 this difference also causes the larges peaks (from one point to another) of SGD while searching for minum loss.
"""