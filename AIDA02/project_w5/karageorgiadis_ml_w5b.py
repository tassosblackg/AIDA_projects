# -*- coding: utf-8 -*-
"""karageorgiadis_ml_w5b.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bwypElmqRhvBaluftSe8PdKvM1VZ0fPs

# ML W5 Fashion Mnist Dataset / Karageorgiadis
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import  Flatten, Dense
from tensorflow.keras import Input
from tensorflow.keras.optimizers import Adam, SGD
from tensorflow.keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical,plot_model
import numpy as np
import matplotlib.pyplot as plt

"""Read Data"""

input_shape = (28,28,1)
output_size = 10

# keras load mnist dataset returns two numpy tuples
(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

# check type and shape
print("Train set shape :",x_train.shape,"data type : ",type(x_train))
print("Test set shape :",x_test.shape,"data type : ",type(x_test))
# Labels shape
print("Train labels shape :",y_train.shape,"data type : ",type(y_train))
print("Test labels shape :",y_test.shape,"data type : ",type(y_test))

"""Preproccessing"""

x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print("Train set shape :",x_train.shape,"data type : ",type(x_train))
print("Test set shape :",x_test.shape,"data type : ",type(x_test))

# Standarazation of input data using z-score method

# calculate mean and std up on train set for all instances
mean_train_set = np.mean(x_train)
std_train_set = np.std(x_train)

#z-score standarization both train and test sets
x_train = (x_train - mean_train_set)/std_train_set
x_test  = (x_test - mean_train_set)/std_train_set

# convert labels to ohe
y_train = to_categorical(y_train,output_size)
y_test = to_categorical(y_test,output_size)

"""Reshape Input"""

model = Sequential()
model.add(Input(input_shape))
model.add(Flatten())
model.add(Dense(64,activation='relu'))
model.add(Dense(128,activation='relu'))
model.add(Dense(output_size,activation='softmax'))

plot_model(model)

print(model.summary())

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

epochs=20
batch_size = 256
history = model.fit(x_train, y_train, validation_split=0.2, epochs = epochs, batch_size = batch_size)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(history.history['val_loss'], label='validation')
plt.plot(history.history['loss'], label='train')
plt.title('Loss')
plt.legend()

scores = model.evaluate(x_test, y_test)
print("&*]\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

"""# Comments

We can see from the figure that while train_accuracy is around *97%* while the test_accuracy is *88%* there is a gap almost of 10%. Increasing batch_size, and number of epochs while the parameters are fewer 

`[59,850 vs 101,770]`

might cause overfitting. So, this model is not perfoming well let's try to change some layers

# **Second Model**
"""

model2 = Sequential()
model2.add(Input(input_shape))
model2.add(Flatten())

model2.add(Dense(256,activation='relu'))
model2.add(Dense(128,activation='relu'))
model2.add(Dense(output_size,activation='softmax'))

plot_model(model2)

print(model2.summary())

model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
epochs=20
batch_size = 256
history2 = model2.fit(x_train, y_train, validation_split=0.2, epochs = epochs, batch_size = batch_size)

plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(history2.history['val_loss'], label='validation')
plt.plot(history2.history['loss'], label='train')
plt.title('Loss')
plt.legend()

scores2 = model2.evaluate(x_test, y_test)
print("&*]\n%s: %.2f%%" % (model2.metrics_names[1], scores2[1]*100))
print("&*]\n%s: %.2f%%" % (model2.metrics_names[0], scores2[0]*100))

"""# Comments
In the second model icreased the width, tested for different bach_sizes, num_of epochs 

icreased total parameters to learn
```
[235,000 vs 101,770]
```
Next step would be to change learning rate from default 0.001 of Adam to something smaller

**Decrease Adam's learning rate =0.0001**
"""

opt = Adam(learning_rate=0.0001)
model2.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])
epochs=20
batch_size = 256
history3 = model2.fit(x_train, y_train, validation_split=0.2, epochs = epochs, batch_size = batch_size)

plt.plot(history3.history['accuracy'])
plt.plot(history3.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

"""As it seems from the above steps **Multi-Level Perceptron** doesn't perform well on the *fashion_mnist* data set, this is becuase the data of this set are more complex, from the classic *mnist*, they have more details to be figured out in order to classify them correctly. It seemes that convolutional neural networks will permorm better in such tasks of image classification.

We also can see [Fashion_Mnist Benchmarks](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/)  for all the benchmarks held for fashion_mnist, to confirm the above, that MLP does not fit.
"""